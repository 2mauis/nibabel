=================================
 Images, headers and code design
=================================

In which we set out how we are thinking of medical image formats and
their commonalities.

Headers
=======

Headers contain two types of information:

#. *howto* data: stuff to tell you how to read the image array data from
   file. This must include the shape of the image array and the numeric
   representation (float32, int16), as well as implicit or explicit
   position of the data relative to the beginning of the data file
   (offset). It can be complicated; ECAT - for example - can contain
   more than one frame, and the datatype can be different for each
   frame.
#. *whatis* data: metadata about the meaning of the image array on file.
   We are interested in the relationship of the voxel positions in the
   data array to space in the real world.  In practice (SPM Analyze,
   NIfTI, MINC) this can always be represented as an affine relating
   voxel coordinates to real world coordinates.  We may also be
   interested in what the 'real world' is.  Neither MINC (1.x) nor
   Analyze stores this, but NIfTI can.


Images
======

We think of an image as being the association of:

#. A data array, of at least three dimensions, where the first three
   dimensions of the array are spatial.
#. A transformation mapping the spatial array (voxel) coordinates to some real
   continuous space (real-world transform).
#. A definition of what this space *is* ('scanner', 'mni', etc).

.. note::

   Why are the first three dimensions spatial?  

   For simplicity, we want the transformation (above) to be spatial.
   Because the images are always at least 3D, and the transform is
   spatial, this means that the tranformation is always exactly 3D.  We
   have to know which of the N image dimensions are spatial. For
   example, if we have a 4D (space and time) image, we need to know
   which of the 4 dimensions are spatial.  We could ask the image to
   tell us, but the simplest thing is to assert which dimensions are
   spatial by convention, and obey that convention with our image
   readers.

   Right, but why the *first* three dimensions?

   Of course, it could be the last three dimensions.  We chose to use
   the first three dimensions because that is the convention encoded in
   the NIfTI standard, at least implicitly, and it will be familiar to
   users of packages like SPM.  Users of Numpy will have a slight
   preference for the first dimension of an array being the slowest
   changing on disk, and the instinct that time, rather than space, will
   usually be the slowest changing dimension on disk, but we didn't want
   to break the NItTI and SPM conventions, on the basis of this
   instinct, because the instinct is difficult to explain to people who
   don't have it.

So, our image likely has::

   img.data
   img.affine
   img.output_space

Lightweight and heavyweight images
==================================

Heavyweight image
-----------------

We've immediately got something obvious for our image class::

   img = Image(data, affine, output_space)

If we're constructing an image in memory, all is simple::

   data = img.data
   affine = img.affine

just does attribute access.

The image contains the full data array (or a reference to it).  This can
be very large, and the image can contain the only reference to the data,
so this is the *heavyweight* image version.

Lightweight image
-----------------

However, when we load an image from disk, we often want to - for
example - look at the affine, or the shape, before either deleting the
image object in memory, or passing the image filename to some other
routine - such as FSL.  In this case we will want to delay a full load of the data because we may not need it, and it is very expensive::

   img = load('some_filename.nii')

Where ``img`` will have some delayed reference scheme for reading the
data iff we need it.

This is the *lightweight* image version, and only arises when there is
some version of the image on disk.


